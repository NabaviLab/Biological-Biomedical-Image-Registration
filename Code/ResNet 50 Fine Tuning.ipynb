{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "In this section of the notebook, we will be fine-tuning a pre-trained ResNet model using our specific dataset. The concept of fine-tuning involves training a pre-existing model, which has been trained on a large dataset, on a new and usually smaller dataset. The idea behind fine-tuning is to harness the features that the pre-existing model has learned, and adapt these to the new task. For this purpose, we are going to use a ResNet model which has been pre-trained on the ImageNet dataset. The ImageNet dataset is a large and diverse dataset which covers a wide variety of categories, and therefore it serves as a good starting point for many vision tasks. During the fine-tuning, we will adjust the final layers of our ResNet model so it can work well with our specific data. We will also decide whether to freeze the initial layers or allow some or all of them to change. By doing this, our model will be able to learn patterns that are specific to our dataset, which could potentially improve its performance."
      ],
      "metadata": {
        "id": "s9gcGC8S7pP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import torch for PyTorch functionality\n",
        "import torch\n",
        "\n",
        "# Import PIL's Image module for image manipulation\n",
        "from PIL import Image\n",
        "\n",
        "# Import transforms and models from torchvision\n",
        "# Transforms module provides common image transformations, \n",
        "# Models provides access to a variety of pre-trained models \n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "# Import DataLoader and Dataset from torch.utils.data\n",
        "# DataLoader wraps an iterable around the Dataset to enable easy access to the samples\n",
        "# Dataset is an abstract class representing a dataset which other datasets should subclass\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "# Import optim module from torch for optimization algorithms\n",
        "# Optim module has various optimization algorithm implementations like Adam, SGD etc.\n",
        "from torch import optim\n",
        "\n",
        "# Import nn module from torch for all neural network modules\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "3vSA2dY-8b2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a custom dataset for handling images\n",
        "class ImageDataset(Dataset):\n",
        "    def __init__(self, image_paths, transform=None):\n",
        "        \"\"\"\n",
        "        Constructor for the ImageDataset class.\n",
        "        Params:\n",
        "            image_paths: A list of paths to images.\n",
        "            transform: Optional torchvision transforms to be applied to the images.\n",
        "        \"\"\"\n",
        "        self.image_paths = image_paths  # Store the list of image paths\n",
        "        self.transform = transform  # Store the transform (if any)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        Returns the length of the dataset, i.e., the number of images.\n",
        "        \"\"\"\n",
        "        return len(self.image_paths)  # Return the number of images\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        Allows indexing into the dataset to get an image.\n",
        "        Params:\n",
        "            idx: An index into the image list.\n",
        "        Returns:\n",
        "            img: A PIL image loaded from the disk and optionally transformed.\n",
        "        \"\"\"\n",
        "        img_path = self.image_paths[idx]  # Get the path to the image at the given index\n",
        "        img = Image.open(img_path).convert(\"RGB\")  # Open the image and convert it to the RGB color space\n",
        "        if self.transform:  # If a transform was provided,\n",
        "            img = self.transform(img)  # apply it to the image\n",
        "        return img  # Return the image\n",
        "\n",
        "\n",
        "# Define the image transformations\n",
        "transform = transforms.Compose([\n",
        "    # Resize the image to 224x224 pixels\n",
        "    transforms.Resize((224, 224)),\n",
        "    \n",
        "    # Convert the image (numpy array) to PyTorch tensor\n",
        "    transforms.ToTensor(),\n",
        "    \n",
        "    # Normalize the image by setting its mean and standard deviation to the given values\n",
        "    # These values are the means and standard deviations of the ImageNet dataset \n",
        "    # on which many pre-trained models are trained\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "\n",
        "\n",
        "# Define the list of image paths you want to process. \n",
        "# Replace the '' with the actual paths to your images. You can add multiple paths separated by commas.\n",
        "image_paths = ['']\n",
        "\n",
        "# Create the custom dataset using the list of image paths and the defined transformation.\n",
        "# The ImageDataset will apply the transformation to each image when it is loaded.\n",
        "dataset = ImageDataset(image_paths, transform=transform)\n",
        "\n",
        "# Create the DataLoader, which allows you to load data in batches and shuffle the data.\n",
        "# batch_size determines how many samples per batch to load.\n",
        "# shuffle set to True means the data will be reshuffled at every epoch.\n",
        "dataloader = DataLoader(dataset, batch_size=4, shuffle=True)\n",
        "\n",
        "# Define the device. If CUDA (a GPU acceleration library) is available, use it. Otherwise, use the CPU.\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load the pre-trained ResNet50 model from torchvision.models.\n",
        "# ResNet50 is a deep convolutional neural network model, widely used for image classification tasks.\n",
        "model = models.resnet50(pretrained=True)\n",
        "\n",
        "\n",
        "# Replace the final fully connected layer of the pre-trained model with a new fully connected layer.\n",
        "# The output features of the new layer are 3 * 224 * 224, assuming the output is an image with dimensions [3, 224, 224].\n",
        "# 'num_ftrs' holds the number of input features for the last layer of the model.\n",
        "num_ftrs = model.fc.in_features\n",
        "model.fc = nn.Linear(num_ftrs, 3 * 224 * 224)\n",
        "\n",
        "# Set the model to training mode.\n",
        "# This is an important step as certain layers such as Dropout or BatchNorm behave differently in training and evaluation modes.\n",
        "model.train()\n",
        "\n",
        "# Move the model to the device (GPU or CPU). \n",
        "# This step ensures that all computations and model parameters are on the specified device for increased efficiency.\n",
        "model = model.to(device)\n",
        "\n",
        "# Define the loss function as Mean Squared Error (MSE) Loss. \n",
        "# MSE Loss is a popular choice for regression problems.\n",
        "criterion = nn.MSELoss()\n",
        "\n",
        "# Define the optimizer as Stochastic Gradient Descent (SGD). \n",
        "# The parameters of the model are passed to the optimizer so that it knows which parameters to update. \n",
        "# Learning rate (lr) is set to 0.001 and momentum is set to 0.9. \n",
        "# Both of these are hyperparameters that might need to be tuned for different datasets or models.\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "\n",
        "# Start the training process\n",
        "for epoch in range(2):  # loop over the entire dataset twice\n",
        "    # Initialize running_loss to 0.0\n",
        "    running_loss = 0.0\n",
        "    # Enumerate over the dataloader which provides batches of images (inputs)\n",
        "    for i, inputs in enumerate(dataloader):\n",
        "        # Move the inputs to the device (GPU or CPU)\n",
        "        inputs = inputs.to(device)\n",
        "\n",
        "        # Reset the gradients of all optimized variables to zero. \n",
        "        # This is done because by default, gradients are accumulated in buffers\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass: compute predicted outputs by passing inputs to the model\n",
        "        outputs = model(inputs)\n",
        "        # Reshape the outputs to match the input image shape, [batch_size, 3, 224, 224]\n",
        "        outputs = outputs.view(-1, 3, 224, 224)\n",
        "\n",
        "        # Compute the loss. Here the loss is computed between the model's outputs and the original inputs \n",
        "        # since we're aiming for the model to regenerate the input image itself (for an autoencoder like model).\n",
        "        loss = criterion(outputs, inputs)\n",
        "\n",
        "        # Backward pass: compute gradient of the loss with respect to model parameters\n",
        "        loss.backward()\n",
        "        # Perform a single optimization step (parameter update)\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update running loss\n",
        "        running_loss += loss.item()\n",
        "        # Print loss statistics every 2000 mini-batches.\n",
        "        if i % 2000 == 1999:  \n",
        "            print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 2000))\n",
        "            # Reset running loss\n",
        "            running_loss = 0.0\n",
        "\n",
        "\n",
        "# Print out that we have finished the training process.\n",
        "print('Finished Training')\n",
        "\n",
        "# After training, we save the learned parameters of the model. \n",
        "# model.state_dict() contains the learned values of the weights and biases for all layers of the model.\n",
        "# We store these parameters in a file 'fine_tuned_model.pth'. \n",
        "# This file can be later loaded to continue training or for inference without having to retrain the model.\n",
        "torch.save(model.state_dict(), 'fine_tuned_model.pth')"
      ],
      "metadata": {
        "id": "uDlMiLyj7p-e"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}